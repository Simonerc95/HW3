{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests as rq\n",
    "import time\n",
    "import random\n",
    "import unicodedata\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import *\n",
    "import string\n",
    "import re\n",
    "from math import *\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "movies = pd.DataFrame(pd.read_html(path + \"\\\\movies-1.html\")[0])\n",
    "movies.drop('Id', inplace=True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(movies)):\n",
    "#     try:\n",
    "#         response = rq.get(movies.URL[i])\n",
    "#     except rq.exceptions.RequestException as e:\n",
    "#         print(e)\n",
    "#         time.sleep(20*60 + 30)\n",
    "#         response = rq.get(movies.URL[i])\n",
    "#     soup = BeautifulSoup(response.text, 'html.parser')\n",
    "#     f = open('article_'+str(i)+'.html','w')\n",
    "#     f.write(str(soup))\n",
    "#     f.close()\n",
    "#     time.sleep(random.choice(range(1,6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = path + '\\\\Articles'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10000):\n",
    "    article = open(path1+'\\\\article_'+str(i)+'.html', 'r')\n",
    "    soup = BeautifulSoup(article, 'html.parser')\n",
    "    d = {}\n",
    "    try:\n",
    "        for x in soup.find('table', class_=\"infobox vevent\").find('th').find_all_next('th'):\n",
    "            d[x.text] = unicodedata.normalize('NFKD',x.next_sibling.get_text(separator = '<br/>').replace('<br/>', ',').strip())\n",
    "    except:\n",
    "        pass\n",
    "    title = str(soup.select('h1')[0].text)\n",
    "\n",
    "    start = soup.find('p')\n",
    "    intro = start.text.strip()\n",
    "    while len(intro) == 0:\n",
    "        start = start.find_next('p')\n",
    "        intro = start.text.strip()\n",
    "    for elem in start.next_siblings:\n",
    "        if elem.name != 'p':\n",
    "            break\n",
    "        intro += elem.text.strip()   \n",
    "\n",
    "    try:\n",
    "        start = soup.find('h2').find_next('p')\n",
    "        plot = start.text.strip()\n",
    "        for elem in start.next_siblings:\n",
    "            if elem.name != 'p':\n",
    "                break\n",
    "            plot += elem.text.strip()\n",
    "\n",
    "    except:\n",
    "        plot = \"NA\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    try :\n",
    "            director = d['Directed by']\n",
    "    except: \n",
    "            director = \"NA\"\n",
    "\n",
    "    try :\n",
    "            producer = d['Produced by']\n",
    "    except: \n",
    "            producer = \"NA\"\n",
    "\n",
    "    try :\n",
    "\n",
    "            writer = d[\"Written by\"]\n",
    "    except:\n",
    "            writer = \"NA\"\n",
    "\n",
    "\n",
    "    try :\n",
    "            starring = d[\"Starring\"].strip()\n",
    "\n",
    "    except:\n",
    "            starring = \"NA\"\n",
    "\n",
    "    try :\n",
    "\n",
    "            music = d[\"Music by\"]\n",
    "    except :\n",
    "            music = \"NA\"\n",
    "\n",
    "    try :\n",
    "            release_date = d[\"Release date\"]\n",
    "\n",
    "    except :\n",
    "\n",
    "            release_date = \"NA\"\n",
    "\n",
    "    try :\n",
    "            run_time = d[\"Running time\"]\n",
    "\n",
    "    except :\n",
    "            run_time = \"NA\"\n",
    "\n",
    "    try :\n",
    "            country = d[\"Country\"]\n",
    "\n",
    "    except :\n",
    "\n",
    "            country = \"NA\"\n",
    "\n",
    "    try :\n",
    "            language = d[\"Language\"]\n",
    "\n",
    "    except:\n",
    "            language = \"NA\"\n",
    "\n",
    "\n",
    "    try :\n",
    "            budget = d[\"Budget\"]\n",
    "\n",
    "    except :\n",
    "            budget = \"NA\"\n",
    "\n",
    "\n",
    "    with open(path+\"\\\\TSV\\\\article_\" + str(i) + \".tsv\", \"w\" ,encoding=\"utf-8\") as out_file:\n",
    "            tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "            tsv_writer.writerow(['title', 'intro', 'plot', 'director', 'producer', 'writer' , 'starring', 'music', 'release_date','run_time', 'country' , 'language' , 'budget'])\n",
    "            tsv_writer.writerow([title, intro, plot, director, producer, writer , starring, music, release_date,run_time, country , language , budget])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20000):\n",
    "    article = open('C:\\\\Users\\\\simon\\\\Desktop\\\\ADM_HW3\\\\' +'article_'+str(i)+'.html', 'r')\n",
    "    soup = BeautifulSoup(article, 'html.parser')\n",
    "    d = {}\n",
    "    try:\n",
    "        for x in soup.find('table', class_=\"infobox vevent\").find('th').find_all_next('th'):\n",
    "            d[x.text] = unicodedata.normalize('NFKD',x.next_sibling.get_text(separator = '<br/>').replace('<br/>', ',').strip())\n",
    "    except:\n",
    "        pass\n",
    "    title = str(soup.select('h1')[0].text)\n",
    "\n",
    "    start = soup.find('p')\n",
    "    intro = start.text.strip()\n",
    "    while len(intro) == 0:\n",
    "        start = start.find_next('p')\n",
    "        intro = start.text.strip()\n",
    "    for elem in start.next_siblings:\n",
    "        if elem.name != 'p':\n",
    "            break\n",
    "        intro += elem.text.strip()   \n",
    "\n",
    "    try:\n",
    "        start = soup.find('h2').find_next('p')\n",
    "        plot = start.text.strip()\n",
    "        for elem in start.next_siblings:\n",
    "            if elem.name != 'p':\n",
    "                break\n",
    "            plot += elem.text.strip()\n",
    "\n",
    "    except:\n",
    "        plot = \"NA\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    try :\n",
    "            director = d['Directed by']\n",
    "    except: \n",
    "            director = \"NA\"\n",
    "\n",
    "    try :\n",
    "            producer = d['Produced by']\n",
    "    except: \n",
    "            producer = \"NA\"\n",
    "\n",
    "    try :\n",
    "\n",
    "            writer = d[\"Written by\"]\n",
    "    except:\n",
    "            writer = \"NA\"\n",
    "\n",
    "\n",
    "    try :\n",
    "            starring = d[\"Starring\"].strip()\n",
    "\n",
    "    except:\n",
    "            starring = \"NA\"\n",
    "\n",
    "    try :\n",
    "\n",
    "            music = d[\"Music by\"]\n",
    "    except :\n",
    "            music = \"NA\"\n",
    "\n",
    "    try :\n",
    "            release_date = d[\"Release date\"]\n",
    "\n",
    "    except :\n",
    "\n",
    "            release_date = \"NA\"\n",
    "\n",
    "    try :\n",
    "            run_time = d[\"Running time\"]\n",
    "\n",
    "    except :\n",
    "            run_time = \"NA\"\n",
    "\n",
    "    try :\n",
    "            country = d[\"Country\"]\n",
    "\n",
    "    except :\n",
    "\n",
    "            country = \"NA\"\n",
    "\n",
    "    try :\n",
    "            language = d[\"Language\"]\n",
    "\n",
    "    except:\n",
    "            language = \"NA\"\n",
    "\n",
    "\n",
    "    try :\n",
    "            budget = d[\"Budget\"]\n",
    "\n",
    "    except :\n",
    "            budget = \"NA\"\n",
    "\n",
    "\n",
    "    with open(path+\"\\\\TSV\\\\article_\" + str(10000 + i) + \".tsv\", \"w\" ,encoding=\"utf-8\") as out_file:\n",
    "            tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "            tsv_writer.writerow(['title', 'intro', 'plot', 'director', 'producer', 'writer' , 'starring', 'music', 'release_date','run_time', 'country' , 'language' , 'budget'])\n",
    "            tsv_writer.writerow([title, intro, plot, director, producer, writer , starring, music, release_date,run_time, country , language , budget])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>intro</th>\n",
       "      <th>plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What Became of Jack and Jill?</td>\n",
       "      <td>What Became of Jack and Jill? is a 1972 Britis...</td>\n",
       "      <td>Johnnie Tallent is a callous young mod who liv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title  \\\n",
       "0  What Became of Jack and Jill?   \n",
       "\n",
       "                                               intro  \\\n",
       "0  What Became of Jack and Jill? is a 1972 Britis...   \n",
       "\n",
       "                                                plot  \n",
       "0  Johnnie Tallent is a callous young mod who liv...  "
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df  = pd.DataFrame(pd.read_csv(path+\"\\\\TSV\\\\article_\" + str(i) + \".tsv\", delimiter = '\\t').iloc[:,0:3])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2 = path+'\\\\TSV\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) \n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear(text):\n",
    "    text = text.lower()\n",
    "    words = word_tokenize(text) #devide the text into substrings\n",
    "    filtered1 = [w for w in words if not w in stop_words] #remove stop words\n",
    "    filtered2 = list(filter(lambda word: word not in string.punctuation, filtered1))\n",
    "    filtered3 = []\n",
    "    for word in filtered2:\n",
    "        try:\n",
    "            filtered3 += re.findall(r'\\w+', word) \n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    filtered3 = [stemmer.stem(w) for w in filtered3] #stemming\n",
    "    filtered4 = [c.replace(\"''\", \"\").replace(\"``\", \"\") for c in filtered3 ] #removing useless '' and  `` characters\n",
    "    filtered4 = [f for f in filtered4 if len(f)>1]\n",
    "    return filtered4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "allwords = list()\n",
    "docwords = dict()\n",
    "for i in range(0,30000):\n",
    "    with open(path2+\"article_\" + str(i) + \".tsv\", encoding = \"utf-8\") as fd:\n",
    "        rd = csv.reader(fd, delimiter=\"\\t\", quotechar='\"')\n",
    "        for row in rd:\n",
    "            if row :\n",
    "                tsv = row\n",
    "    text = ' '.join([tsv[1],tsv[2]])\n",
    "    \n",
    "    cleared = clear(text)\n",
    "        \n",
    "    docwords['document_'+str(i)] = cleared\n",
    "    allwords += cleared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = {}   \n",
    "allwords = list(set(allwords))\n",
    "for i in range(len(allwords)):\n",
    "    vocabulary[str(i)] = allwords[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_voc = {v:k for k,v in vocabulary.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "inverted = defaultdict(list)\n",
    "for doc in docwords.keys():\n",
    "    for word in docwords[doc]:\n",
    "        if not doc in inverted[reverse_voc[word]]:\n",
    "            inverted[reverse_voc[word]].append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + \"\\\\WORDS\\\\DocWords.json\", \"w\" ,encoding=\"utf-8\") as out_file:\n",
    "    out_file.write(json.dumps(docwords, ensure_ascii = False))\n",
    "with open(path + \"\\\\WORDS\\\\vocabulary.json\", \"w\" ,encoding=\"utf-8\") as out_file:\n",
    "    out_file.write(json.dumps(vocabulary, ensure_ascii=False))\n",
    "with open(path + \"\\\\WORDS\\\\Inverted_index.json\", \"w\" ,encoding=\"utf-8\") as out_file:\n",
    "    out_file.write(json.dumps(inverted, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF Inverted Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + \"\\\\WORDS\\\\Inverted_index.json\", encoding = \"utf-8\") as fd:\n",
    "        inverted_index = json.load(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + \"\\\\WORDS\\\\DocWords.json\", encoding = \"utf-8\") as fd:\n",
    "        data = json.load(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = []\n",
    "inv_ind_tfIDF = defaultdict(list)\n",
    "for term in inverted_index.keys() :\n",
    "        idf = log(1+ 30000/len(inverted_index[term]))\n",
    "        for doc in inverted_index[term] :\n",
    "            tf = data[doc].count(vocabulary[term]) / len(data[doc])\n",
    "            tfidf = tf * idf\n",
    "            inv_ind_tfIDF[term].append((doc,round(tfidf, 3)))\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path+\"\\\\WORDS\\\\tfidf_index.json\", \"w\", encoding = \"utf8\") as myfile:\n",
    "    myfile.write(json.dumps(inv_ind_tfIDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2 = path+'\\\\TSV\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "allwords = set(allwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Starring': '9',\n",
       " 'Release Year': '2007',\n",
       " 'Runtime': '122',\n",
       " 'Budget': '55000000'}"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(path2+'article_15048.tsv', encoding = 'utf8') as fd:\n",
    "    rd = csv.reader(fd, delimiter=\"\\t\", quotechar='\"')\n",
    "    for row in rd:\n",
    "        if row :\n",
    "            tsv = row\n",
    "            \n",
    "d = {}\n",
    "\n",
    "if tsv[6] == 'NA':\n",
    "    d['Starring'] = '0'\n",
    "else:\n",
    "    d['Starring'] = str(len(tsv[6].split(',')))\n",
    "\n",
    "try:\n",
    "    d['Release Year'] = re.search(r'\\d{4}', tsv[8]).group(0)\n",
    "except:\n",
    "    d['Release Year'] = '0'\n",
    "    \n",
    "try:\n",
    "    d['Runtime']      = re.search(r'\\d+.*',tsv[9]).group(0)\n",
    "except:\n",
    "    d['Runtime']    = '0'\n",
    "\n",
    "#some movies have running time expressed in reels, and the conversion in minutes is not univoque, so we'll just ignore those info\n",
    "if re.search(r'min', d['Runtime']):\n",
    "    d['Runtime'] = re.search(r'\\d+[\\.|\\,|:]*\\d*', d['Runtime']).group(0)\n",
    "    d['Runtime'] = re.search(r'\\d+', d['Runtime']).group(0)\n",
    "else:\n",
    "    d['Runtime'] = '0'\n",
    "    \n",
    "try:\n",
    "    d['Budget']   = re.findall(r'\\$.*', tsv[12])[0]\n",
    "except:\n",
    "    d['Budget']  = '0'\n",
    "\n",
    "if re.search(r'mil', d['Budget']):\n",
    "    d['Budget']  = str(int(float(re.search(r'\\d+[\\.|\\,]*\\d*', d['Budget']).group(0))*10**6))\n",
    "elif re.search(r',', d['Budget']):\n",
    "    d['Budget'] = d['Budget'].replace(',', '').replace('$', '')\n",
    "else:\n",
    "    d['Budget'] = d['Budget'].replace('.', '').replace('$', '')\n",
    "\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8625010781263477"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = dict()\n",
    "q['runtime'] = 150\n",
    "Runtimes = [6,12,15,57,100,132]\n",
    "minrun = min(Runtimes)\n",
    "maxrun = max(Runtimes)\n",
    "if d['Runtime'] != 0:\n",
    "    runscore = 1 - abs(int(q['runtime'])- int(d['Runtime']))/(maxrun - minrun)\n",
    "else:\n",
    "    runscore = 0\n",
    "runscore\n",
    "\n",
    "maxbud = 400000000\n",
    "minbud = 500\n",
    "q['Budget'] = \"expensive\"\n",
    "\n",
    "if q['Budget'] == 'expensive':\n",
    "    bud_score = (maxbud - int(d['Budget']))/(maxbud-minbud)\n",
    "elif q['Budget'] == 'inexpensive':\n",
    "    bud_score = (int(d['Budget']) - minbud)/(maxbud-minbud)\n",
    "    \n",
    "bud_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you prefer an old movie or a new-released movie? Please type O for Old and N for New:O\n",
      "Do you want to specify the release year ?Please type Y for Yes and N for No: Y\n",
      "please specify the release date1924\n",
      "Do you want to specify the length of the movie? Please type Y for Yes and N for No:Y\n",
      "please specify the length of the movie120\n",
      "Is number of stars an important factor for you? Please type Y for Yes and N for No:Y\n",
      "Is movie budget an important factor for you? Please type Y for Yes and N for No:10\n"
     ]
    }
   ],
   "source": [
    "q = dict()\n",
    "oldnew = input(\"Do you prefer an old movie or a new-released movie? Please type O for Old and N for New:\")\n",
    "if oldnew == \"O\" :\n",
    "    q[\"release\"] = \"O\"\n",
    "if oldnew == \"N\" :\n",
    "    q[\"release\"] = \"N\"\n",
    "    \n",
    "    \n",
    "    \n",
    "year = input(\"Do you want to specify the release year ?Please type Y for Yes and N for No: \")\n",
    "if year == \"N\" :\n",
    "    q[\"year\"] = \"NA\"\n",
    "if year == \"Y\" :\n",
    "    year = input(\"please specify the release date\") \n",
    "    q[\"year\"] = year\n",
    "    \n",
    "    \n",
    "\n",
    "Runtime = input(\"Do you want to specify the length of the movie? Please type Y for Yes and N for No:\")\n",
    "if Runtime == \"N\" :\n",
    "    q[\"Runtime\"] = \"NA\"\n",
    "if Runtime == \"Y\" :\n",
    "    Runtime = input(\"please specify the length of the movie\")\n",
    "    q[\"Runtime\"] = Runtime\n",
    "    \n",
    "    \n",
    "starring = input(\"Is number of stars an important factor for you? Please type Y for Yes and N for No:\")\n",
    "q[\"starring\"] = starring\n",
    "\n",
    "\n",
    "budget = input(\"Is movie budget an important factor for you? Please type Y for Yes and N for No:\")\n",
    "q[\"budget\"] = budget\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
